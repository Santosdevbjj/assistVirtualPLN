## Criando sistema de assistÃªncia virtual, utilizando PLN - Processamento de Linguagem Natural.

![bairesDev](https://github.com/user-attachments/assets/5917d3f6-cd14-4f9e-9e36-68a0d71e1aa1)



**Bootcamp BairesDev - Machine Learning Training.**

---

ğŸ¤– **Assistente Virtual com PLN**



ğŸ“– **DescriÃ§Ã£o do Projeto**
Este projeto Ã© um sistema de assistÃªncia virtual desenvolvido do zero, utilizando Processamento de Linguagem Natural (PLN) para interagir com o usuÃ¡rio por meio de comandos de voz. O assistente Ã© capaz de ouvir, interpretar a fala e responder, alÃ©m de executar aÃ§Ãµes automatizadas.

**As principais funcionalidades incluem:**

**Text-to-Speech (TTS):** ConversÃ£o de texto para Ã¡udio para que o assistente possa "falar".
   
  **Speech-to-Text (STT):** ConversÃ£o de Ã¡udio do microfone para texto, permitindo a compreensÃ£o dos comandos do usuÃ¡rio.
 * AutomaÃ§Ã£o: ExecuÃ§Ã£o de tarefas como pesquisar na Wikipedia, abrir o YouTube e buscar locais no Google Maps, acionadas por comandos de voz.

ğŸ’» **Tecnologias e Bibliotecas Utilizadas**

| Tecnologia/Biblioteca | DescriÃ§Ã£o |
|---|---|
| Python | Linguagem de programaÃ§Ã£o principal. |
| SpeechRecognition | Para a conversÃ£o de fala em texto, utilizando a API de reconhecimento de voz do Google. |
| pyttsx3 | Para a conversÃ£o de texto em fala, com suporte a diferentes motores de voz (TTS). |
| PyAudio | Biblioteca de baixo nÃ­vel para gravaÃ§Ã£o de Ã¡udio, necessÃ¡ria para o SpeechRecognition capturar a entrada do microfone. |
| Wikipedia | Para realizar buscas e obter resumos de artigos na Wikipedia. |
| webbrowser | MÃ³dulo nativo do Python para abrir URLs e interagir com o navegador web do sistema. |

âš™ï¸ **Requisitos**

**Requisitos de Software**

  - Python 3.8+
  - pip (gerenciador de pacotes do Python)
    
**Requisitos de Hardware**

- Microfone (integrado ou externo) para a funcionalidade de Speech-to-Text.
- Alto-falantes ou fones de ouvido para a funcionalidade de Text-to-Speech.

   
ğŸš€ **Como Rodar o Projeto**

Siga estes passos para configurar e executar o projeto em seu ambiente local.

**1. Clonar o RepositÃ³rio**
git clone https://github.com/Santosdevbjj/assistVirtualPLN.git
cd assistVirtualPLN

**2. Instalar as DependÃªncias**
Ã‰ altamente recomendÃ¡vel utilizar um ambiente virtual para isolar as dependÃªncias do projeto.

# Cria um ambiente virtual (venv)
python -m venv .venv

# Ativa o ambiente virtual
# No Windows:
.venv\Scripts\activate
# No macOS/Linux:
source .venv/bin/activate

# Instala as bibliotecas a partir do arquivo requirements.txt
pip install -r requirements.txt

**AtenÃ§Ã£o:** A instalaÃ§Ã£o de PyAudio pode requerer a instalaÃ§Ã£o prÃ©via de bibliotecas como portaudio-devel no Linux ou pipwin no Windows. Caso tenha problemas, consulte a documentaÃ§Ã£o da biblioteca.

**3. Executar o Assistente**
ApÃ³s a instalaÃ§Ã£o das dependÃªncias, vocÃª pode rodar o assistente virtual.
python src/main.py

O assistente irÃ¡ comeÃ§ar a ouvir por comandos. Tente dizer algo como:

 * "Pesquisar por inteligÃªncia artificial"
 * "Abra o YouTube"
 * "Onde fica a farmÃ¡cia mais prÃ³xima"
 * "Parar"

---
   
ğŸ“‚ **Estrutura do Projeto**
A organizaÃ§Ã£o do projeto segue uma estrutura modular para facilitar o desenvolvimento e a manutenÃ§Ã£o.
assistVirtualPLN/
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ audio_input/      # Pasta para armazenar arquivos de Ã¡udio de teste.
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_speech_recognition.ipynb # Notebook de demonstraÃ§Ã£o de Speech-to-Text.
â”‚   â””â”€â”€ 02_text_to_speech.ipynb     # Notebook de demonstraÃ§Ã£o de Text-to-Speech.
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py       # Marca 'src' como um pacote Python.
â”‚   â”œâ”€â”€ core_functions.py # ContÃ©m as funÃ§Ãµes principais do assistente (TTS, STT, aÃ§Ãµes).
â”‚   â””â”€â”€ main.py           # O ponto de entrada principal do programa.
â”‚
â”œâ”€â”€ .gitignore            # Ignora arquivos e pastas que nÃ£o devem ser versionados.
â”œâ”€â”€ README.md             # Este arquivo.
â”œâ”€â”€ requirements.txt      # Lista de dependÃªncias do projeto.
â””â”€â”€ setup.py              # Arquivo de configuraÃ§Ã£o para empacotar o projeto.


---

**DescriÃ§Ã£o dos Arquivos e Pastas**

 - **assets/:** Pasta para armazenar recursos nÃ£o-cÃ³digo, como Ã¡udios para testes.

- **notebooks/:** ContÃ©m notebooks Jupyter que podem ser executados no Google Colab, ideais para prototipagem e demonstraÃ§Ãµes isoladas das funcionalidades de voz.
 
- **src/:** DiretÃ³rio principal com o cÃ³digo-fonte do assistente.

- **__init__.py:** Essencial para que o Python reconheÃ§a src como um pacote, permitindo importaÃ§Ãµes.
   
- **core_functions.py:** O "cÃ©rebro" do assistente, onde as funÃ§Ãµes de conversÃ£o de voz e as aÃ§Ãµes automatizadas estÃ£o definidas.
   
- **main.py:** O arquivo que orquestra o fluxo do programa, chamando as funÃ§Ãµes de core_functions.py com base nos comandos do usuÃ¡rio.
 
 - **.gitignore:** Garante que arquivos de cache, ambientes virtuais e configuraÃ§Ãµes de IDEs nÃ£o sejam incluÃ­dos no controle de versÃ£o.

- **requirements.txt:** Lista as bibliotecas Python com suas respectivas versÃµes, garantindo que o ambiente de desenvolvimento seja o mesmo para todos os colaboradores.
 
 - **setup.py:** Transforma o projeto em um pacote Python, permitindo sua instalaÃ§Ã£o via pip.
   
âœï¸ **ContribuiÃ§Ã£o**
ContribuiÃ§Ãµes sÃ£o bem-vindas! Se vocÃª tiver sugestÃµes, melhorias ou encontrar bugs, sinta-se Ã  vontade para abrir uma issue ou enviar um pull request para o repositÃ³rio.


ğŸ“„ **LicenÃ§a**
Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT.


 
