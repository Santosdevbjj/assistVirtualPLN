{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "COLLAB_NOTEBOOK",
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Santosdevbjj/assistVirtualPLN/blob/main/notebooks/01_speech_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_zYt0q4u7l3"
   },
   "source": [
    "# **Notebook 01: Demonstração de Speech-to-Text**\n",
    "\n",
    "Este notebook demonstra como utilizar a biblioteca `SpeechRecognition` em Python para converter áudio capturado do microfone em texto. Este é o componente central para o funcionamento de um assistente virtual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI8_T-lsu-rQ"
   },
   "source": [
    "### **1. Instalação das Bibliotecas**\n",
    "\n",
    "Primeiro, instalamos as bibliotecas necessárias. O `SpeechRecognition` é a principal, e o `PyAudio` é necessário para o acesso ao microfone."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l9c7k4Wlu-3G"
   },
   "source": [
    "# Instala as bibliotecas SpeechRecognition e PyAudio\n",
    "!pip install SpeechRecognition\n",
    "!pip install PyAudio"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d87aE9J-vE0b"
   },
   "source": [
    "### **2. Função de Reconhecimento de Fala**\n",
    "\n",
    "Definimos uma função para encapsular a lógica de ouvir e reconhecer a fala. Esta função utiliza o serviço de reconhecimento de voz do Google por ser robusto e gratuito."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1yC8qGzlvPzW"
   },
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def listen_and_recognize():\n",
    "    \"\"\"\n",
    "    Captura áudio do microfone e o converte em texto usando o Google Speech Recognition.\n",
    "    Retorna o texto reconhecido ou None em caso de erro.\n",
    "    \"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Por favor, diga algo...\")\n",
    "        # Ajusta para o ruído ambiente para melhorar a qualidade do reconhecimento\n",
    "        r.adjust_for_ambient_noise(source, duration=1)\n",
    "        try:\n",
    "            audio = r.listen(source, timeout=5, phrase_time_limit=5)\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"Nenhuma fala detectada. Tente novamente.\")\n",
    "            return None\n",
    "\n",
    "    print(\"Processando...\\n\")\n",
    "    try:\n",
    "        # Reconhece a fala usando o Google Web Speech API\n",
    "        text = r.recognize_google(audio, language='pt-BR')\n",
    "        print(f\"Você disse: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Desculpe, não consegui entender o áudio.\")\n",
    "        return None\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Erro no serviço de reconhecimento de fala; {e}\")\n",
    "        return None"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84_0rE-Yve5P"
   },
   "source": [
    "### **3. Teste da Função**\n",
    "\n",
    "Agora, execute a função e veja o resultado. Certifique-se de que seu navegador tenha permissão para usar o microfone."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6qT2M3iMvhhv"
   },
   "source": [
    "recognized_text = listen_and_recognize()\n",
    "if recognized_text:\n",
    "    print(\"\\nReconhecimento concluído.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_XqY4QJvr_S"
   },
   "source": [
    "### **Conclusão**\n",
    "\n",
    "Este é o primeiro passo para o seu assistente virtual. O texto retornado pela função `listen_and_recognize()` pode ser usado para tomar decisões e acionar outras funções, como pesquisar na Wikipedia ou abrir um vídeo no YouTube, conforme visto no arquivo `src/main.py`."
   ]
  }
 ]
}
